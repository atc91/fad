---
title: "Proyecto Final Fundamentos de Analítica"
output: html_notebook
---

# Problema

Usted es el encargado de analítica de una empresa de telefonía celular y tiene que proporcionar soluciones para hacer frente a las problemáticas de un sector que ha llegado a saturación del mercado. Tanto su empresa como sus competidores directos tienen que disputarse por una base de clientes limitada, de tal forma que usted tiene que responder a un objetivo estratégico definido por la dirección así: 

“Mantener y fidelizar a nuestros clientes por medio de un servicio de calidad que se adapte a sus necesidades particulares.”

Su compañía dispone de una base de datos histórica de personas que hace un año eran clientes propios. Algunos de esos clientes siguen siéndolo hoy en día, otros ya no lo son.

Se han identificado dos proyectos de analítica de datos que permitirán alcanzar tal objetivo, que tendrá que desarrollar en las dos partes siguientes. 


## Parte 1

Cree un modelo predictivo de deserción que permita identificar los clientes propensos a irse a las empresas en directa competencia con la suya en el próximo año.

### 1. ¿Encuentra alguna anomalía en los datos? (0.3)



```{r}
library(ggplot2)
library(caret)
library(corrplot)
library(fpc)
library(cluster)
library("factoextra")
library(data.table)
```

```{r}
clientes <- data.frame(read.csv("PF-02-DatosTelco.csv", header = TRUE))
head(clientes)
```

Vamos a analizar entonces las variables numéricas para evaluar que tipo de preprocesamientos debemos hacer para no influenciar de manera inadecuada los análisis que realizaremos.
```{r}
str(clientes)
summary(clientes)
apply(clientes[, -c(1)], 2, mean)

apply(clientes[, -c(1)], 2, var)
```

Podemos ver que las variables tienen promedios muy diferentes, que impedirán a los algoritmos de clustering (basados en distancia)
encontrar estructuras adecuadas. Además, podemos ver también que las varianzas son muy diferentes, lo que influenciaría negativamente la búsqueda de los componente principales de PCA, que se basa en la dispersión de los datos. Vamos entonces a estandarizar los datos para arreglar estos problemas.

```{r}
modelo_std<- preProcess(clientes, method = c("center", "scale"))
clientes_std <- predict(modelo_std, clientes)
head(clientes_std)
```


```{r}
ggplot(stack(clientes_std), aes(x = ind, y = values)) + geom_boxplot(aes(fill=ind))

```
Podemos ver que en las variables CASA, PRECIO_DISPOSITIVO y MESES presentan valores atipicios.

### 2. La empresa considera que los valores de variables que estén a más de 4 desviaciones estándar del promedio deberían ser consideradas excepcionales, y por lo tanto no se deben considerar en los análisis. Identifíquelas y apártelas del dataset (0.3)


Como todos los datos estan estandarizados, su varianza es 1:

```{r}
apply(clientes_std[, -c(1)], 2, var)
```

Calculamos la desviacion de los datos estandarizados:
```{r}
means = apply(clientes_std[, -c(1)], 2, mean)
means
```

Para encontrar los outliers basta con saber cuales superan de maginutud 4 veces la media de cada variable

```{r}
indicesAQuitarNuevos <- which( abs(clientes_std$PRECIO_DISPOSITIVO) > means["PRECIO_DISPOSITIVO"] + 4)
clientes_std[indicesAQuitarNuevos,]
```

Puede que un cliente sea excepcional en varias variables, por lo que no queremos eliminar de nuestro análisis más clientes de lo necesario. Vamos a analizar entonces variable por variable los clientes excepcionales y a guardar sus índices en el dataframe progresivamente, para poder eliminarlos al final.


```{r}
indicesAQuitar <- NULL 
indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)

indicesAQuitarNuevos <- which( abs(clientes_std$INGRESOS) > means["INGRESOS"] + 4)
indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)


indicesAQuitarNuevos <- which( abs(clientes_std$CASA) > means["CASA"] + 4)
indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)

indicesAQuitarNuevos <- which( abs(clientes_std$MESES)> means["MESES"] + 4)

indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)
indicesAQuitarNuevos <- which( abs(clientes_std$DURACION) > means["DURACION"] + 4)

indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)
indicesAQuitarNuevos <- which( abs(clientes_std$SOBRECARGO) > means["SOBRECARGO"] + 4)

indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)
indicesAQuitarNuevos <- which( abs(clientes_std$SALDO_RESTANTE) > means["SALDO_RESTANTE"] + 4)

indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)
indicesAQuitarNuevos <- which( abs(clientes_std$SATISFACCION) > means["SATISFACCION"] + 4)

indicesAQuitar <- union(indicesAQuitar, indicesAQuitarNuevos)

length(indicesAQuitar)
```

Hay en total 4 clientes que serán ignorados por el análisis, todos atipicios en la variable PRECIO_DISPOSITIVO:
```{r}
clientes_std = clientes_std[-indicesAQuitar,]
```


### 3. Analice la correlación entre las variables y explique lo que puede implicar desde el punto de vista de PCA. (0.2)


```{r}
corMat <- cor(clientes_std[, -c(1)])
corrplot(corMat, type="upper", order="hclust")

```

Se ve una fuere correlacion entre SOBRECARGO-SATISFACCION, INGRESOS-SALDO_RESTANTE
Una correlacion moderada entre CASA-INGRESOS-SALDO_RESTANTE
Una correlacion debile entre INGRESOS-DURACION

Esto puede implicar que con solo 2 o 3(de 7)
componentes principales se pueda tene un modelo con poca perdida de información.

### 4. Debe entrenar 3 tipos de modelos predictivos de diferentes familias:

#### a. Defina el protocolo de evaluación que va a utilizar para calibrar los modelos y estimar la calidad del modelo final. (0.3)

Vamos a particionar aleatoriamente "a mano" el dataset, sacando una muestra aleatoria del 75% de los datos (17369 registros) para el entrenamiento y el resto para el test con la función createDataPartition de Caret. Inicializamos el generador aleatorio para poder garantizar reproducibilidad.
```{r}
set.seed(3456) 
trainIndex <- createDataPartition(clientes[-indicesAQuitar,]$ESTADO, p = .75, list = FALSE, times = 1)

train <- clientes[ trainIndex,]
test <-  clientes[-trainIndex,]
```


El protocolo de evaluacion del modelo va a ser repeated K-Fold cross-validation

```{r}
cctrl <- trainControl(method="repeatedcv", 
                      repeats=5, 
                      number=5, 
                      summaryFunction = twoClassSummary,
                      classProbs = TRUE )
```

#### b. Establezca las métricas que va a utilizar, justificando su escogencia (0.2)

Queremos identificar los clientes mas propensos a irse a la competencia directa de la empresa, por tanto es mas costoso decir que el cliente permanece VINCULADO cuando en realidad se RETIRA que decir que el cliente se RETIRA cuando permanece VINCULADO. 

Entonces queremos optimizar el modelo para que identifique lo mejor posible los verdaderos negativos(RETIRA) y la metrica que vamos a usar es la specificity especificidad.

#### c. Calibre 3 tipos de modelos diferentes: K-NN, árbol de decisión y algún otro que propongan, utilizando las métricas y protocolo definido (1.0)

```{r}
library(MASS)
```


Modelo KNN
```{r}
model_knn <- train(ESTADO ~., data = train,
                     method = "knn", 
                     trControl = cctrl,
                     preProcess=c("center", "scale"),
                     tuneGrid=expand.grid(k=c(15, 25, 35, 45, 55, 65, 75, 85)),
                     metric="Spec")
model_knn
```
Modelo 2
```{r}
model_rpart <- train(ESTADO ~., data = train,
                     method = "rpart", 
                     trControl = cctrl,
                     preProcess=c("center", "scale"),
                     metric="Spec")
model_rpart
```

Modelo regresión logística

```{r}
model_glm <- train(ESTADO ~., data = train,
                   method = "glmStepAIC",
                   trControl = cctrl,
                   preProcess=c("center", "scale"),
                   metric="Spec")
model_glm
```
#### d. Evalúe los 3 modelos encontrados, escoja el mejor, explicando y concluyendo lo que encontró, utilizando las métricas y protocolo definido (0.5)

Modelo KNN
```{r}
predictions_knn<-predict(object=model_knn, test)
confusionMatrix(predictions_knn, test$ESTADO)
```

Modelo arbol de desicion
```{r}
predictions_rpart<-predict(object=model_rpart, test)
confusionMatrix(predictions_rpart, test$ESTADO)
``` 

Modelo regresion logistica
```{r}
predictions_glm<-predict(object=model_glm, test)
confusionMatrix(predictions_glm, test$ESTADO)
```

Los 3 modelos tienen resultados similares tanto en especifidad como en Accuracy y Kappa.
Por velocidad en entraneamiento, evaluacion, recalibracion automatica escogemos el modelo de regresion logistica como el mas adecuado.
